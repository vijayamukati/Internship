{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72caeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "from sklearn.model_selection import  train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder,power_transform\n",
    "from sklearn.model_selection import  train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve,roc_auc_score,classification_report\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"C:\\Users\\deepak.mukati\\OneDrive\\Desktop\\Internship\\Malignant Comments Classifier Project\\train.csv\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197382a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(r\"C:\\Users\\deepak.mukati\\OneDrive\\Desktop\\Internship\\Malignant Comments Classifier Project\\test.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbcf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_test, df_train])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c31a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can handle missing data by filling them with 'No Review' using fillna()\n",
    "df['malignant'].fillna(0,inplace=True)\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65220eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['malignant'].fillna(0,inplace=True)\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f066a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['highly_malignant'].fillna(0,inplace=True)\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rude'].fillna(0,inplace=True)\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c6862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['threat'].fillna(0,inplace=True)\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loathe'].fillna(0,inplace=True)\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06df7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abuse'].fillna(0,inplace=True)\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adb038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape    #Checking the dimensions of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['malignant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['highly_malignant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['threat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['abuse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf966486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['loathe'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097aea7",
   "metadata": {},
   "source": [
    "From the above observations, we can see that its an imbalanced dataset and we need to handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading test data\n",
    " \n",
    "df_test.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1333b2",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting countplot for all the features\n",
    "categories=df_train.columns[2:]\n",
    "for col in categories:\n",
    "    sns.countplot(df_train[col])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9de3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the percentage of the comments\n",
    "none = df_train[(df_train['malignant']!=1) & (df_train['highly_malignant']!=1) & (df_train['rude']!=1) & \n",
    "                            (df_train['threat']!=1) & (df_train['abuse']!=1) & (df_train['loathe']!=1)]\n",
    "percent=len(none)/len(df_train)*100\n",
    "print('Percentage of good/neutral comments = ',percent)\n",
    "print('Percentage of negative comments = ', (100-percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the number of counts for every target label\n",
    "counts=df_train.iloc[:,2:].sum()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b303cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the counts of each category\n",
    "plt.figure(figsize=(12,4))\n",
    "ax = sns.barplot(counts.index, counts.values)\n",
    "plt.title(\"Counts of Categories\")\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlabel('Category ', fontsize=12)\n",
    "rects = ax.patches\n",
    "labels = counts.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb759db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the label distribution of comments using pie chart\n",
    "comments_labels = ['malignant', 'highly_malignant', 'rude', 'threat', 'abuse', 'loathe']\n",
    "df_distribution = df_train[comments_labels].sum()\\\n",
    "                            .to_frame()\\\n",
    "                            .rename(columns={0: 'count'})\\\n",
    "                            .sort_values('count')\n",
    "\n",
    "df_distribution.plot.pie(y = 'count', title = 'Label distribution over comments', autopct='%.2f', figsize = (10, 10))\\\n",
    "                            .legend(loc='center left', bbox_to_anchor=(1.3, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18aa4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of comments length\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(10,7))\n",
    "comment_len = df_train.comment_text.str.len()\n",
    "sns.distplot(comment_len, bins=20, color = 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting distplot for checking the distribution of data\n",
    "for col in df_train.describe().columns:\n",
    "    sns.distplot(df_train[col])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b781ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking correlation of the dataset\n",
    "corr=df_train.corr()  #corr() function provides the correlation value of each column\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting heatmap for visualizing the correlation\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr,linewidth=0.5,linecolor='black',fmt='.0%',cmap='YlGn_r',annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85768a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As ID is not much important, we can drop from the dataset\n",
    "df.drop(columns=['id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac94e2d",
   "metadata": {},
   "source": [
    "Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8279fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a 'label' column in the train dataset\n",
    "#Label column is the sum of all the target features\n",
    "comments_labels = ['malignant', 'highly_malignant', 'rude', 'threat', 'abuse', 'loathe']\n",
    "df_train[comments_labels].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6cfa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label']=df_train[comments_labels].sum(axis=1)\n",
    "df_train.head(10)  #Checking the dataset after adding it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331962af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the count of labels\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(df_train['label'], palette='coolwarm')\n",
    "plt.title('Counting of the labels',fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d302e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that 0 has more number of weightage, whereas 6 has the lesser weightage\n",
    "\n",
    "#Scaling the label column\n",
    "df_train['label'] = df_train['label'] >0\n",
    "df_train['label'] = df_train['label'].astype(int)\n",
    "df_train.head(15)    #Checking the data after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020750e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the counting of labels after scaling\n",
    "print(df_train['label'].value_counts())\n",
    "sns.countplot(df_train['label'], palette='rainbow')\n",
    "plt.title('Counting of the labels after scaling',fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dada8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After scaling the data, we can see that 0 has more weightage and 1 has lesser weightage\n",
    "\n",
    "#Creating a column 'length_before_cleaning' in training dataset\n",
    "#It represents the length of the each comment respectively in a column 'comment_text' \n",
    "df_train['length_before_cleaning'] = df_train['comment_text'].map(lambda comment_text: len(comment_text))\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72bf7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column 'length_before_cleaning' in test dataset\n",
    "#It represents the length of the each comment respectively in a column 'comment_text' \n",
    "df_test['length_before_cleaning'] = df_test['comment_text'].map(lambda comment_text: len(comment_text))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81c32b",
   "metadata": {},
   "source": [
    "Preprocessing using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f27e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required libraries\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca411ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#Replacing '\\n' in comment_text\n",
    "df_train['comment_text'] = df_train['comment_text'].replace('\\n',' ')\n",
    "#Function Definition for using regex operations and other text preprocessing for getting cleaned texts\n",
    "def clean_comments(text):\n",
    "   #convert to lower case\n",
    "    lowered_text = text.lower()\n",
    "    \n",
    "    #Replacing email addresses with 'emailaddress'\n",
    "    text = re.sub(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddress', lowered_text)\n",
    "    \n",
    "    #Replace URLs with 'webaddress'\n",
    "    text = re.sub(r'http\\S+', 'webaddress', text)\n",
    "    \n",
    "    #Removing numbers\n",
    "    text = re.sub(r'[0-9]', \" \", text)\n",
    "    \n",
    "    #Removing the HTML tags\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    \n",
    "    #Removing Punctuations\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\_',' ',text)\n",
    "    \n",
    "    #Removing all the non-ascii characters \n",
    "    clean_words = re.sub(r'[^\\x00-\\x7f]',r'', text)\n",
    "    \n",
    "    #Removing the unwanted white spaces\n",
    "    text = \" \".join(text.split()) \n",
    "    \n",
    "    #Splitting data into words\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    \n",
    "    #Removing remaining tokens that are not alphabetic, Removing stop words and Lemmatizing the text\n",
    "    removed_stop_text = [lemmatizer.lemmatize(word) for word in tokenized_text if word not in stop_words if word.isalpha()]\n",
    "   \n",
    "    return \" \".join(removed_stop_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the above function for the column comment_text in training dataset to replace original with cleaned text\n",
    "df_train['comment_text'] = df_train['comment_text'].apply(clean_comments)\n",
    "df_train['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column 'len_after_cleaning'\n",
    "#Representing the length of the each comment respectively in a column 'comment_text' after cleaning the text.\n",
    "df_train['len_after_cleaning'] = df_train['comment_text'].map(lambda comment_text: len(comment_text))\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Total length removal in train dataset\n",
    "print(\"Original Length:\", df_train.length_before_cleaning.sum())\n",
    "print(\"Cleaned Length:\", df_train.len_after_cleaning.sum())\n",
    "print(\"Total Words Removed:\", (df_train.length_before_cleaning.sum()) - (df_train.len_after_cleaning.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a119762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the above function for the column comment_text in test dataset so that we can replace original with cleaned text\n",
    "df_test['comment_text'] = df_test['comment_text'].apply(clean_comments)\n",
    "df_test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ba265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column 'len_after_cleaning'\n",
    "#It represents the length of the each comment respectively in a column 'comment_text' after cleaning the text\n",
    "df_test['len_after_cleaning'] = df_test['comment_text'].map(lambda comment_text: len(comment_text))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ea45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total length removal in test dataset\n",
    "print('Original Length:',df_test.length_before_cleaning.sum())\n",
    "print('Clean Length:',df_test.len_after_cleaning.sum())\n",
    "print(\"Total Words Removed:\", (df_test.length_before_cleaning.sum()) - (df_test.len_after_cleaning.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba44423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_malignant=df_train[(df_train['malignant']==1)]\n",
    "df_malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting for malignant\n",
    "wordcloud=WordCloud(height=400,width=400,max_words=400).generate(str(df_malignant['comment_text']))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.title(label='WORDS TAGGED AS MALIGNANT',fontdict={'fontsize':50, 'fontweight':50, 'color':'red'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1fc5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highlymalignant=df_train[(df_train['highly_malignant']==1)]\n",
    "df_highlymalignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d82b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting for highly_malignant\n",
    "wordcloud=WordCloud(height=400,width=400,max_words=400).generate(str(df_highlymalignant['comment_text']))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.title(label='WORDS TAGGED AS HIGHLY MALIGNANT',fontdict={'fontsize':50, 'fontweight':50, 'color':'red'})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rude=df_train[(df_train['rude']==1)]\n",
    "df_rude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33121976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting for rude\n",
    "wordcloud=WordCloud(height=400,width=400,max_words=400).generate(str(df_rude['comment_text']))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.title(label='WORDS TAGGED AS RUDE',fontdict={'fontsize':50, 'fontweight':50, 'color':'red'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2297012",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threat=df_train[(df_train['threat']==1)]\n",
    "df_threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3190a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting for threat\n",
    "wordcloud=WordCloud(height=400,width=400,max_words=400).generate(str(df_threat['comment_text']))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.title(label='WORDS TAGGED AS THREAT',fontdict={'fontsize':50, 'fontweight':50, 'color':'red'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0da847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abuse=df_train[(df_train['abuse']==1)]\n",
    "df_abuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting for abuse\n",
    "wordcloud=WordCloud(height=400,width=400,max_words=400).generate(str(df_abuse['comment_text']))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.title(label='WORDS TAGGED AS ABUSE',fontdict={'fontsize':50, 'fontweight':50, 'color':'red'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a34738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loathe=df_train[(df_train['loathe']==1)]\n",
    "df_loathe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting for loathe\n",
    "wordcloud=WordCloud(height=400,width=400,max_words=400).generate(str(df_loathe['comment_text']))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.title(label='WORDS TAGGED AS LOATHE',fontdict={'fontsize':50, 'fontweight':50, 'color':'red'})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db0117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating independent and dependent variables\n",
    "#Converting the features into number vectors\n",
    "tf_vec = TfidfVectorizer(max_features = 15000, stop_words='english')\n",
    "#Let's Separate the input and output variables represented by X and y respectively in train data and convert them\n",
    "X = tf_vec.fit_transform(df_train['comment_text'])\n",
    "y=df_train['label']\n",
    "print(X.shape,'\\t\\t', y.shape)    #Checking the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da99a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the above process for test data \n",
    "test_vec = tf_vec.fit_transform(df_test['comment_text'])\n",
    "test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa5c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "#Splitting the training and testing data \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "#Checking the shape of x data\n",
    "print(x_train.shape,'\\t\\t',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of y data\n",
    "print(y_train.shape,'\\t',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61343cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling the imbalanced data using oversampling technique\n",
    "#Importing the Oversampling library and Counter\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "#We are trying to increase the points of minimum label data\n",
    "os = RandomOverSampler(0.75)\n",
    "x_train_os,y_train_os = os.fit_resample(x_train,y_train)\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_os)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97382196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import hamming_loss, log_loss\n",
    "#Initializing the instance of the model\n",
    "LR=LogisticRegression()\n",
    "mnb=MultinomialNB()\n",
    "dtc=DecisionTreeClassifier()\n",
    "knc=KNeighborsClassifier()\n",
    "rfc=RandomForestClassifier()\n",
    "abc=AdaBoostClassifier()\n",
    "gbc=GradientBoostingClassifier()\n",
    "xgb=XGBClassifier()\n",
    "models= []\n",
    "models.append(('Logistic Regression',LR))\n",
    "models.append(('MultinomialNB',mnb))\n",
    "models.append(('DecisionTreeClassifier',dtc))\n",
    "models.append(('KNeighborsClassifier',knc))\n",
    "models.append(('RandomForestClassifier',rfc))\n",
    "models.append(('AdaBoostClassifier',abc))\n",
    "models.append(('GradientBoostingClassifier',gbc))\n",
    "models.append(('XGBoostClassifier',xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114eff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Making a for loop and calling the algorithm one by one and save data to respective model using append function\n",
    "Model=[]\n",
    "score=[]\n",
    "cvs=[]\n",
    "rocscore=[]\n",
    "h_loss=[]\n",
    "l_loss=[]\n",
    "for name,model in models:\n",
    "    print('******************************',name,'***************************')-\n",
    "    print('\\n')\n",
    "    Model.append(name)\n",
    "    model.fit(x_train_os,y_train_os)\n",
    "    print(model)\n",
    "    pre=model.predict(x_test)\n",
    "    print('\\n')\n",
    "    AS=accuracy_score(y_test,pre)\n",
    "    print('accuracy_score: ',AS)\n",
    "    score.append(AS*100)\n",
    "    print('\\n')\n",
    "    sc=cross_val_score(model,X,y,cv=5,scoring='accuracy').mean()\n",
    "    print('cross_val_score: ',sc)\n",
    "    cvs.append(sc*100)\n",
    "    print('\\n')\n",
    "    false_positive_rate,true_positive_rate,thresholds=roc_curve(y_test,pre)\n",
    "    roc_auc= auc(false_positive_rate,true_positive_rate)\n",
    "    print('roc_auc_score: ',roc_auc)\n",
    "    rocscore.append(roc_auc*100)\n",
    "    print('\\n')\n",
    "    hloss = hamming_loss(y_test, pre)\n",
    "    print(\"Hamming_loss:\", hloss)\n",
    "    h_loss.append(hloss)\n",
    "    print('\\n')\n",
    "    try : \n",
    "        loss = log_loss(y_test, pre)\n",
    "    except :\n",
    "            loss = log_loss(y_test, pre.toarray())   \n",
    "    print(\"Log_loss :\", loss)\n",
    "    l_loss.append(loss)\n",
    "    print('\\n')\n",
    "    print('Classification report:\\n ')\n",
    "    print(classification_report(y_test,pre))\n",
    "    print('\\n')\n",
    "    print('Confusion matrix: \\n')\n",
    "    cm=confusion_matrix(y_test,pre)\n",
    "    print(cm)\n",
    "    print('\\n')\n",
    "    plt.figure(figsize=(10,50))\n",
    "    plt.subplot(912)\n",
    "    print('AUC_ROC curve:\\n')\n",
    "    plt.title(name)\n",
    "    plt.plot(false_positive_rate,true_positive_rate, label='AUC = %0.2f'% roc_auc)\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalizing the result\n",
    "result=pd.DataFrame({'Model':Model, 'Accuracy_score': score,'Cross_val_score':cvs,'roc_auc_score':rocscore,\n",
    "                    'Hamming_loss':h_loss, 'Log_loss':l_loss})\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c961a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning\n",
    "#Random Forest Classifier\n",
    "#Creating parameter list to pass in GridSearchCV\n",
    "parameters={'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10],'n_estimators': [50, 100, 500]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfc=RandomForestClassifier(random_state=42)   #Using the best random state we obtained\n",
    "rfc=GridSearchCV(rfc,parameters,cv=3,scoring='accuracy')\n",
    "rfc.fit(x_train_os,y_train_os)\n",
    "print(rfc.best_params_)     #Printing the best parameters obtained\n",
    "print(rfc.best_score_)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train_os,y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=rfc.predict(x_test)\n",
    "print('Accuracy score: ',accuracy_score(y_test,pre)*100)\n",
    "print('Cross validation score: ',cross_val_score(rfc,X,y,cv=5,scoring='accuracy').mean()*100)\n",
    "false_positive_rate,true_positive_rate,thresholds=roc_curve(y_test,pre)\n",
    "roc_auc= auc(false_positive_rate,true_positive_rate)\n",
    "print('roc_auc_score: ',roc_auc)\n",
    "hloss = hamming_loss(y_test, pre)\n",
    "print(\"Hamming_loss:\", hloss)\n",
    "loss = log_loss(y_test, pre)\n",
    "print(\"Log loss:\", loss)\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(y_test,pre))\n",
    "print('Confusion matrix: \\n')\n",
    "print(confusion_matrix(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b92764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC_ROC Curve of Randomforest Classifier with oversampled data\n",
    "y_pred_prob=rfc.predict_proba(x_test)[:,1]\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_prob)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr,label='RandomForest Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('RandomForest Classifier')\n",
    "plt.show()\n",
    "\n",
    "auc_score=roc_auc_score(y_test,rfc.predict(x_test))\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9671da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Finalizing the model\n",
    "rfc_prediction=rfc.predict(X)\n",
    "#Making a dataframe of predictions\n",
    "malignant_prediction=pd.DataFrame({'Predictions':rfc_prediction})\n",
    "malignant_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "import pickle\n",
    "filename='MalignantCommentsClassifier_Project.pkl'   #Specifying the filename\n",
    "pickle.dump(rfc,open(filename,'wb'))  \n",
    "Predicting using test data\n",
    "#Checking our vectorized test data\n",
    "test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06447e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "fitted_model=pickle.load(open('MalignantCommentsClassifier_Project.pkl','rb'))\n",
    "fitted_model\n",
    "RandomForestClassifier()\n",
    "#Predictions\n",
    "test_prediction=rfc.predict(test_vec)\n",
    "test_df=pd.DataFrame({'Predictions':test_prediction})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Saving the predictions\n",
    "#Test predictions\n",
    "test_results=pd.DataFrame(test_df)\n",
    "test_results.to_csv('Malignant_TestDataPredictions.csv')\n",
    "#Train predictions\n",
    "malignant_prediction.to_csv('Malignant_TrainDataPredictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978554ac",
   "metadata": {},
   "source": [
    "Finally, we had predicted over the test data and the predictions obtained were saved in a csv file.\n",
    "\n",
    "Conclusion\n",
    "-> After the completion of this project, we got an insight of how to preprocess the data, analyzing the data and building a model.\n",
    "\n",
    "-> First, we imported both training and testing data, which had nearly 150000+ records.\n",
    "\n",
    "-> We did all the required pre-processing steps like checking null values, datatypes check, dropping unnecessary columns, etc.\n",
    "\n",
    "-> We used the training data for doing Exploratory Data Analysis using various plots and recorded the observations.\n",
    "\n",
    "-> While observing the results, we found that the dataset was in highly imbalanced side and we need to handle it, in order to avoid overfitting problem.\n",
    "\n",
    "-> Using NLP, we pre-processed the comment text and did other steps like:\n",
    "\n",
    "Removing Punctuations and other special characters\n",
    "\n",
    "Splitting the comments into individual words\n",
    "\n",
    "Removing Stop Words\n",
    "\n",
    "Stemming and Lemmatising\n",
    "\n",
    "Applying Count Vectoriser\n",
    "\n",
    "Plotting wordclod for knowing the weightage of words used\n",
    "\n",
    "-> The above steps were done simultaneously for both training and testing data\n",
    "\n",
    "-> As the problem was a multi-class classifier, we took a new feature known as label and combined the comment_labels output together using sum() and then stored in that feature. For a binary classification problem, we scaled the data accordingly.\n",
    "\n",
    "-> After applying Tf-idf Vectoriser, we used an oversampling technique called RandomOverSampler for handling the imbalanced data. There, we took 75% of the high\n",
    "points data and sampled it to the low points data so that both weights could be balanced equally and we could get proper result.\n",
    "\n",
    "-> Then, we split the data using train_test_split and then we started the model building process by running as many algorithms in a for loop, with difference metrics like cross_val_score, confusion matrix, auc_score, log loss, hamming loss, etc.\n",
    "\n",
    "-> We found that RandomForestClassifier and XGBoostClassifier were performing well. The next step was to perform hyperparameter tuning technique to these models for finding out the best parameters and trying to improve our scores.\n",
    "\n",
    "-> The major problem with this dataset occured in this step. It took me nearly 2 hrs to run the code for finding out the best parameters itself as the dataset is large and more computational power was required. Even though we found the best algorithms, it took me 2 hrs to get the results.\n",
    "\n",
    "-> Therefore, without hyperparameter tuning, we finalized RandomForest as the best performing algorithm by predicting the outputs, saving the model and storing the results in a csv file\n",
    "\n",
    "-> Then, by using the model we got, another set of predictions were done by using the test data and the results were stored in a separate csv file.\n",
    "\n",
    "Problems faced while working in this project:\n",
    "More computational power was required as it took more than 2 hours\n",
    "\n",
    "Imbalanced dataset and bad comment texts\n",
    "\n",
    "Good parameters could not be obtained using hyperparameter tuning as time was consumed more\n",
    "\n",
    "Areas of improvement:\n",
    "Could be provided with a good dataset which doesnot take more time.\n",
    "\n",
    "Less time complexity\n",
    "\n",
    "Providing a proper balanced dataset with less errors.\n",
    " My point of view from my project is that we need to use proper words which are respectful and also avoid using abusive, vulgar and worst words in social media. It can cause many problems which could affect our lives. Try to be polite, calm and composed while handling stress and negativity and one of the best solution is to avoid it and overcoming in a positive manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15eaa02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103246c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32383724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4636af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
